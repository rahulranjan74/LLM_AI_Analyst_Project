# LLM_AI_Analyst_Project

About :
This is an application that takes in the name of a company as input (in the form of the ticker name as listed in the official US stock exchange) and then automatically downloads the 10-K filings of the company from the last 29 years from the Securities Exchange Commissions(SEC) websites and provides insights based on inferencing by an LLM. To make the application I have used the principles of Retrieval Augmented Generation(RAG) where the the additional text pieces of information extracted from the 10-K filings are provided to the LLM for context and the LLM uses its reasoning capabilities to come up with insights. The word embeddings are generated by the "sentence-transformers/all-MiniLM-L6-v2" transformer, the Vector Store used was "FAISS" from Meta and the LLM model used was Meta's latest "Meta-Llama-3-8B-Instruct", called as an API. Finally all this backend was put together in the form of an application using the streamlit library which was used to make the GUI for the application,

Libraries Used :
sec_edgar_downloader -> to download the 10K filings
BeautifulSoup -> to extract the text data from the XML format 10k filings. (HTML parsing)
Langchain -> to make the pipelines for asking the questions to the Language Models and RAG. Also, the Hugging Face hosted models were accessed through the built-in langchain.llms HuggingFaceEndpoint() function.
Streamlit -> To make the Graphics User Interface for the application.
Further Improvements :
The insights from the LLMs were very generic and didn't provide precise and unique info. Possible cause was the output limit set by the HuggingFace Inference API endpoint. A possible solution would be to run the LLM locally using Quantized Weights.
The textual data provided to the LLMs in the form of embeddings was poorly formatted due to the vague format of the 10K filings downloaded from the SEC website. More specific preprocessing was not possible due to the variations of data locations in the filings of different companies.
